{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-gh00yjCWOCl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AlbertForMaskedLM, AlbertTokenizer\n",
    "from transformers import AlbertForPreTraining, AlbertForMaskedLM\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AdamW\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "m6AKeRq8XO3x"
   },
   "outputs": [],
   "source": [
    "mujeres = pd.read_csv(\"tweets_mujeres.csv\",usecols=['id','tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hombres = pd.read_csv(\"tweets_hombres.csv\",usecols=['id','tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=201038, step=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mujeres.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "remove_n = len(hombres) - len(mujeres)\n",
    "drop_indices = np.random.choice(hombres.index, remove_n, replace=False)\n",
    "hombres = hombres.drop(drop_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EOxt5Hkco1jt"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96be416bf1a84129ac0acb5e4d6359c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/828 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136ff3f0fe8544b8ba100c9d5ee80a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/20.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at CenIA/albert-tiny-spanish were not used when initializing AlbertForMaskedLM: ['sop_classifier.classifier.bias', 'sop_classifier.classifier.weight']\n",
      "- This IS expected if you are initializing AlbertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at CenIA/albert-tiny-spanish were not used when initializing AlbertForMaskedLM: ['sop_classifier.classifier.bias', 'sop_classifier.classifier.weight']\n",
      "- This IS expected if you are initializing AlbertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "albeto = \"CenIA/albert-tiny-spanish\"\n",
    "\n",
    "tokenizer_h = AlbertTokenizer.from_pretrained(albeto, \n",
    "                        return_offset_mapping=True)\n",
    "model_h = AlbertForMaskedLM.from_pretrained(albeto, return_dict=True)\n",
    "\n",
    "tokenizer_m = AlbertTokenizer.from_pretrained(albeto, \n",
    "                        return_offset_mapping=True)\n",
    "model_m = AlbertForMaskedLM.from_pretrained(albeto, return_dict=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201038"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hombres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j14agRBtsoW0",
    "outputId": "248e6e49-e8f9-4062-f9d0-160539140878"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='CenIA/albert-tiny-spanish', vocab_size=31000, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '<unk>', 'sep_token': '[SEP]', 'pad_token': '<pad>', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xheuKzK2o1gr"
   },
   "outputs": [],
   "source": [
    "def preprocess_function_mujeres(examples):\n",
    "    inputs = [ex for ex in examples[\"mujeres_tweet\"]]\n",
    "    #targets = [ex for ex in examples[\"hombres_tweet\"]]\n",
    "\n",
    "    model_inputs = tokenizer_m(inputs,\n",
    "                        #text_pair=targets,\n",
    "                        padding=\"max_length\", \n",
    "                        truncation=True,\n",
    "                        max_length=280,\n",
    "                        return_tensors='pt'\n",
    "                        )\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "def preprocess_function_hombres(examples):\n",
    "    #inputs = [ex for ex in examples[\"mujeres_tweet\"]]\n",
    "    inputs = [ex for ex in examples[\"hombres_tweet\"]]\n",
    "\n",
    "    model_inputs = tokenizer_h(inputs,\n",
    "                        #text_pair=targets,\n",
    "                        padding=\"max_length\", \n",
    "                        truncation=True,\n",
    "                        max_length=280,\n",
    "                        return_tensors='pt'\n",
    "                        )\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "w2JqshF5o1eC"
   },
   "outputs": [],
   "source": [
    "def tokenize_sentences_mujeres(mujeres):\n",
    "    data = {\"mujeres_tweet\":list(mujeres.tweet)\n",
    "        #\"hombres_tweet\":list(hombres.tweet)\n",
    "           }\n",
    "    raw_dataset = pd.DataFrame(data)\n",
    "\n",
    "    ds = Dataset.from_pandas(raw_dataset,preserve_index=True)\n",
    "    ds = ds.rename_column('__index_level_0__','id')\n",
    "    ds = ds.train_test_split(shuffle = True, seed = 200, test_size=0.2)\n",
    "\n",
    "    train_set = preprocess_function_mujeres(ds[\"train\"])\n",
    "    test_set = preprocess_function_mujeres(ds[\"test\"])\n",
    "    \n",
    "    train_set['labels'] = train_set['input_ids'].detach().clone()\n",
    "    test_set['labels'] = test_set['input_ids'].detach().clone()\n",
    "    \n",
    "    return train_set, test_set\n",
    "            \n",
    "            \n",
    "def tokenize_sentences_hombres(hombres):\n",
    "    data = {#\"mujeres_tweet\":list(mujeres.tweet),\n",
    "        \"hombres_tweet\":list(hombres.tweet)}\n",
    "    raw_dataset = pd.DataFrame(data)\n",
    "\n",
    "    ds = Dataset.from_pandas(raw_dataset,preserve_index=True)\n",
    "    ds = ds.rename_column('__index_level_0__','id')\n",
    "    ds = ds.train_test_split(shuffle = True, seed = 200, test_size=0.2)\n",
    "\n",
    "    train_set = preprocess_function_hombres(ds[\"train\"])\n",
    "    test_set = preprocess_function_hombres(ds[\"test\"])\n",
    "    \n",
    "    train_set['labels'] = train_set['input_ids'].detach().clone()\n",
    "    test_set['labels'] = test_set['input_ids'].detach().clone()\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k3FzB7a5o1bx",
    "outputId": "edf4b0f3-885b-4896-edb0-eb75121402b5"
   },
   "outputs": [],
   "source": [
    "trainingSet_mujeres, testSet_mujeres= tokenize_sentences_mujeres(mujeres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet_hombres, testSet_hombres= tokenize_sentences_hombres(hombres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haciendo BETO para mujeres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = trainingSet_mujeres[\"input_ids\"]\n",
    "input_ids[0][7] = tokenizer_m.mask_token_id\n",
    "\n",
    "labels = trainingSet_mujeres[\"input_ids\"].clone()\n",
    "labels[labels!= tokenizer_m.mask_token_id] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TFiyi5DEo1ZN"
   },
   "outputs": [],
   "source": [
    "class TweetsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_ids = self.encodings['input_ids'][index]\n",
    "        labels = self.encodings['labels'][index]\n",
    "        attention_mask = self.encodings['attention_mask'][index]\n",
    "        token_type_ids = self.encodings['token_type_ids'][index]\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'labels': labels,\n",
    "            'attention_mask': attention_mask,\n",
    "            'token_type_ids': token_type_ids\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Q1ejsPe1o1Wz"
   },
   "outputs": [],
   "source": [
    "dataset_mujeres = TweetsDataset(trainingSet_mujeres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = testSet_mujeres[\"input_ids\"]\n",
    "input_ids[0][7] = tokenizer_m.mask_token_id\n",
    "\n",
    "labels = testSet_mujeres[\"input_ids\"].clone()\n",
    "labels[labels!= tokenizer_m.mask_token_id] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetsDataset2(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_ids = self.encodings['input_ids'][index]\n",
    "        labels = self.encodings['labels'][index]\n",
    "        attention_mask = self.encodings['attention_mask'][index]\n",
    "        token_type_ids = self.encodings['token_type_ids'][index]\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'labels': labels,\n",
    "            'attention_mask': attention_mask,\n",
    "            'token_type_ids': token_type_ids\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_mujeres = TweetsDataset2(testSet_mujeres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ptAVp6iHo1VE"
   },
   "outputs": [],
   "source": [
    "def get_dataloader(dataset_mujeres):\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "      dataset_mujeres,\n",
    "      batch_size=32,\n",
    "      shuffle=True,\n",
    "    num_workers=5\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "def get_Testdataloader(test_dataset_mujeres):\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "      test_dataset_mujeres,\n",
    "      batch_size=16,\n",
    "      shuffle=True,\n",
    "    num_workers=5\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Seh3pDF8o1TA"
   },
   "outputs": [],
   "source": [
    "Data_loader_train_mujeres = get_dataloader(dataset_mujeres)\n",
    "Data_loader_test_mujeres = get_Testdataloader(test_dataset_mujeres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5eqtH51oo1Qz",
    "outputId": "87afcff4-79d8-492c-f224-7dc6884f1f91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "L2EfwmAso1M5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlbertForMaskedLM(\n",
       "  (albert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(31000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=312, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=312, out_features=1248, bias=True)\n",
       "              (ffn_output): Linear(in_features=1248, out_features=312, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (predictions): AlbertMLMHead(\n",
       "    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=312, out_features=128, bias=True)\n",
       "    (decoder): Linear(in_features=128, out_features=31000, bias=True)\n",
       "    (activation): GELUActivation()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ctgt79kKvK_l",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from transformers import AdamW\n",
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-FTQKPSo1Jx",
    "outputId": "c605079b-01f5-4626-bf9c-5d135d693493"
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "optimizer = torch.optim.AdamW(model_m.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPQCv7z10G7a",
    "outputId": "130e4f23-e574-48ca-e0cc-14e2c426b76a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "3xehjsTU0Lsl"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    corr = torch.corrcoef(pred)\n",
    "    return corr.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(Data_loader_train_mujeres):\n",
    "    global losses_list_train\n",
    "    global perplexity_list_train\n",
    "    \n",
    "    losses_list_train = []\n",
    "    perplexity_list_train = []\n",
    "    \n",
    "    model_m.train()\n",
    "    \n",
    "    loop = tqdm(Data_loader_train_mujeres)\n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        outputs = model_m(input_ids=input_ids,\n",
    "                        labels=labels,\n",
    "                        attention_mask = attention_mask,\n",
    "                        token_type_ids = token_type_ids)\n",
    "        loss = outputs.loss\n",
    "        x = outputs.logits\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        try:\n",
    "            perplexity = torch.exp(loss)\n",
    "        except OverflowError:\n",
    "            perplexity = torch.tensor(float(\"inf\"))\n",
    "        corr = compute_metrics(x.view(-1))\n",
    "\n",
    "        loop.set_description(\"Epoch: {}\".format(epoch))\n",
    "        loop.set_postfix(loss=loss.item(), corr = corr, perplexity=perplexity.item())\n",
    "        \n",
    "        losses_list_train.append(loss.item())\n",
    "        perplexity_list_train.append(perplexity.item())\n",
    "    return outputs\n",
    "\n",
    "def test(Data_loader_test_mujeres):\n",
    "    global losses_list_test\n",
    "    global perplexity_list_test\n",
    "    \n",
    "    losses_list_test = []\n",
    "    perplexity_list_test = []\n",
    "    \n",
    "    model_m.eval()\n",
    "    loop = tqdm(Data_loader_test_mujeres)\n",
    "    \n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        outputs = model_m(input_ids=input_ids,\n",
    "                        labels=labels,\n",
    "                        attention_mask = attention_mask,\n",
    "                        token_type_ids = token_type_ids)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        try:\n",
    "            perplexity = torch.exp(loss)\n",
    "        except OverflowError:\n",
    "            perplexity = torch.tensor(float(\"inf\"))\n",
    "        \n",
    "        x = outputs.logits\n",
    "        corr = compute_metrics(x.view(-1))\n",
    "\n",
    "        loop.set_description(\"Epoch: {}\".format(epoch))\n",
    "        loop.set_postfix(loss=loss.item(), corr=corr, perplexity= perplexity.item())\n",
    "        \n",
    "        losses_list_test.append(loss.item())\n",
    "        perplexity_list_test.append(perplexity.item())\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(columns=[\"stage\",\"loss\",\"perplexity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\"stage\":[],\"loss\":[],\"perplexity\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect gc\n",
      "Empty cache\n",
      "Training BETO\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2af6f28580b4d1cad1e0bbe837dceb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train metrics...\n",
      "Collect gc\n",
      "Empty cache\n",
      "Test phase\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9606572273314d24af83a4e91a854ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test metrics...\n",
      "Collect gc\n",
      "Empty cache\n",
      "Training BETO\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed62e6051d849e2825bc39e1d567092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train metrics...\n",
      "Collect gc\n",
      "Empty cache\n",
      "Test phase\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d41f98a9ebc4581a57604a26eaa3b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test metrics...\n",
      "Collect gc\n",
      "Empty cache\n",
      "Training BETO\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22d68a3cb874800ace2625df8e9a7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train metrics...\n",
      "Collect gc\n",
      "Empty cache\n",
      "Test phase\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f158ae141140c0ac2972ea17b5c71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test metrics...\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(\"Collect gc\")\n",
    "    gc.collect()\n",
    "    print(\"Empty cache\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"Training alBETO\")\n",
    "    training(Data_loader_train_mujeres)\n",
    "    \n",
    "    print(\"Saving train metrics...\")\n",
    "    \n",
    "    dic[\"stage\"].append([\"training \" +str(epoch)])\n",
    "    dic[\"loss\"].append([losses_list_train])\n",
    "    dic[\"perplexity\"].append([perplexity_list_train])\n",
    "    \n",
    "    \n",
    "    print(\"Collect gc\")\n",
    "    gc.collect()\n",
    "    print(\"Empty cache\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    print(\"Test phase\")\n",
    "    test(Data_loader_test_mujeres)\n",
    "    \n",
    "    print(\"Saving test metrics...\")\n",
    "    dic[\"stage\"].append([\"testing \" +str(epoch)])\n",
    "    dic[\"loss\"].append([losses_list_test])\n",
    "    dic[\"perplexity\"].append([perplexity_list_test])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_m.save_pretrained('./my_model_checkpoints_ellas_albeto/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./my_model_checkpoints_ellas_albeto/tokenizer_config.json',\n",
       " './my_model_checkpoints_ellas_albeto/special_tokens_map.json',\n",
       " './my_model_checkpoints_ellas_albeto/spiece.model',\n",
       " './my_model_checkpoints_ellas_albeto/added_tokens.json')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_m.save_pretrained('./my_model_checkpoints_ellas_albeto/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@adams_zulema Muchas gracias @adams_zulema ❤️ saludos'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mujeres.tweet.to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def encode(df):\n",
    "    data = df.tweet.to_numpy()\n",
    "    print(\"Encoding the corpus. This might take a while\")\n",
    "    embeddings = []\n",
    "    for sentence in data:\n",
    "        corpus_embeddings = tokenizer_m.encode(sentence)\n",
    "        corpus_embeddings = corpus_embeddings / np.linalg.norm(corpus_embeddings,keepdims=True)\n",
    "        embeddings.append(corpus_embeddings)\n",
    "        \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding the corpus. This might take a while\n"
     ]
    }
   ],
   "source": [
    "mujeres_embeddings = encode(mujeres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2.1279776843082054e-05, 0.3290279095477347, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2.7469421058294175e-05, 0.42473218840334453, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2.800252040332407e-05, 0.43297497047619676, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2.0192240340570886e-05, 0.31221242014590705, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2.1764793073813686e-05, 0.3365272305073072, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201033</th>\n",
       "      <td>[2.777929830192188e-05, 0.42952351034431613, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201034</th>\n",
       "      <td>[1.910993855813517e-05, 0.29547786998588604, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201035</th>\n",
       "      <td>[2.6823751208130837e-05, 0.414748841180119, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201036</th>\n",
       "      <td>[1.8651467192103727e-05, 0.2883889857243078, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201037</th>\n",
       "      <td>[1.767082254615648e-05, 0.27322625820867147, 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201038 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       [2.1279776843082054e-05, 0.3290279095477347, 1...\n",
       "1       [2.7469421058294175e-05, 0.42473218840334453, ...\n",
       "2       [2.800252040332407e-05, 0.43297497047619676, 1...\n",
       "3       [2.0192240340570886e-05, 0.31221242014590705, ...\n",
       "4       [2.1764793073813686e-05, 0.3365272305073072, 1...\n",
       "...                                                   ...\n",
       "201033  [2.777929830192188e-05, 0.42952351034431613, 1...\n",
       "201034  [1.910993855813517e-05, 0.29547786998588604, 9...\n",
       "201035  [2.6823751208130837e-05, 0.414748841180119, 1....\n",
       "201036  [1.8651467192103727e-05, 0.2883889857243078, 9...\n",
       "201037  [1.767082254615648e-05, 0.27322625820867147, 8...\n",
       "\n",
       "[201038 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_encoded = pd.DataFrame([mujeres_embeddings]).T\n",
    "datos_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos_encoded.columns = [\"Mujeres\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_m = AlbertForMaskedLM.from_pretrained('./my_model_checkpoints_ellas_albeto/', return_dict=True)\n",
    "\n",
    "tokenizer_m = AlbertTokenizer.from_pretrained('./my_model_checkpoints_ellas_albeto/', \n",
    "                        return_offset_mapping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_encoded.to_csv(\"./my_model_checkpoints_ellas/embeddings_albeto.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haciendo BETO para hombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = trainingSet_hombres[\"input_ids\"]\n",
    "input_ids[0][7] = tokenizer_h.mask_token_id\n",
    "\n",
    "labels = trainingSet_hombres[\"input_ids\"].clone()\n",
    "labels[labels!= tokenizer_h.mask_token_id] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hombres = TweetsDataset(trainingSet_hombres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = testSet_hombres[\"input_ids\"]\n",
    "input_ids[0][7] = tokenizer_h.mask_token_id\n",
    "\n",
    "labels = testSet_hombres[\"input_ids\"].clone()\n",
    "labels[labels!= tokenizer_h.mask_token_id] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_hombres = TweetsDataset2(testSet_hombres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(dataset_hombres):\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "      dataset_hombres,\n",
    "      batch_size=32,\n",
    "      shuffle=True,\n",
    "    num_workers=5\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "def get_Testdataloader(test_dataset_hombres):\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "      test_dataset_hombres,\n",
    "      batch_size=16,\n",
    "      shuffle=True,\n",
    "    num_workers=5\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_loader_train_hombres = get_dataloader(dataset_hombres)\n",
    "Data_loader_test_hombres = get_Testdataloader(test_dataset_hombres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlbertForMaskedLM(\n",
       "  (albert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(31000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=312, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=312, out_features=1248, bias=True)\n",
       "              (ffn_output): Linear(in_features=1248, out_features=312, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (predictions): AlbertMLMHead(\n",
       "    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=312, out_features=128, bias=True)\n",
       "    (decoder): Linear(in_features=128, out_features=31000, bias=True)\n",
       "    (activation): GELUActivation()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_h.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "optimizer = torch.optim.AdamW(model_h.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    corr = torch.corrcoef(pred)\n",
    "    return corr.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(Data_loader_train_hombres):\n",
    "    global losses_list_train\n",
    "    global perplexity_list_train\n",
    "    \n",
    "    losses_list_train = []\n",
    "    perplexity_list_train = []\n",
    "    \n",
    "    model_h.train()\n",
    "    \n",
    "    loop = tqdm(Data_loader_train_hombres)\n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        outputs = model_h(input_ids=input_ids,\n",
    "                        labels=labels,\n",
    "                        attention_mask = attention_mask,\n",
    "                        token_type_ids = token_type_ids)\n",
    "        loss = outputs.loss\n",
    "        x = outputs.logits\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        try:\n",
    "            perplexity = torch.exp(loss)\n",
    "        except OverflowError:\n",
    "            perplexity = torch.tensor(float(\"inf\"))\n",
    "        corr = compute_metrics(x.view(-1))\n",
    "\n",
    "        loop.set_description(\"Epoch: {}\".format(epoch))\n",
    "        loop.set_postfix(loss=loss.item(), corr = corr, perplexity=perplexity.item())\n",
    "        \n",
    "        losses_list_train.append(loss.item())\n",
    "        perplexity_list_train.append(perplexity.item())\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(Data_loader_test_hombres):\n",
    "    global losses_list_test\n",
    "    global perplexity_list_test\n",
    "    \n",
    "    losses_list_test = []\n",
    "    perplexity_list_test = []\n",
    "    \n",
    "    model_h.eval()\n",
    "    loop = tqdm(Data_loader_test_hombres)\n",
    "    \n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        outputs = model_h(input_ids=input_ids,\n",
    "                        labels=labels,\n",
    "                        attention_mask = attention_mask,\n",
    "                        token_type_ids = token_type_ids)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        try:\n",
    "            perplexity = torch.exp(loss)\n",
    "        except OverflowError:\n",
    "            perplexity = torch.tensor(float(\"inf\"))\n",
    "        \n",
    "        x = outputs.logits\n",
    "        corr = compute_metrics(x.view(-1))\n",
    "\n",
    "        loop.set_description(\"Epoch: {}\".format(epoch))\n",
    "        loop.set_postfix(loss=loss.item(), corr=corr, perplexity= perplexity.item())\n",
    "        \n",
    "        losses_list_test.append(loss.item())\n",
    "        perplexity_list_test.append(perplexity.item())\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic2 = {\"stage\":[],\"loss\":[],\"perplexity\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect gc\n",
      "Empty cache\n",
      "Training alBETO\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca17081219649128ec45a503fc069b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train metrics...\n",
      "Collect gc\n",
      "Empty cache\n",
      "Test phase\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047071098feb40698e28c61fa3453ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test metrics...\n",
      "Collect gc\n",
      "Empty cache\n",
      "Training alBETO\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c8f6bb923742868d4aadeb76139075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train metrics...\n",
      "Collect gc\n",
      "Empty cache\n",
      "Test phase\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332d8fe23756474b86bf5a82db24c7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty cache\n",
      "Training alBETO\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b3a4122fbf4d69b18b4a5c9cd02e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train metrics...\n",
      "Collect gc\n",
      "Empty cache\n",
      "Test phase\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24f38e39e0044bb8e82d5694e48aedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test metrics...\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(\"Collect gc\")\n",
    "    gc.collect()\n",
    "    print(\"Empty cache\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"Training alBETO\")\n",
    "    training(Data_loader_train_hombres)\n",
    "    \n",
    "    print(\"Saving train metrics...\")\n",
    "    \n",
    "    dic2[\"stage\"].append([\"training \" +str(epoch)])\n",
    "    dic2[\"loss\"].append([losses_list_train])\n",
    "    dic2[\"perplexity\"].append([perplexity_list_train])\n",
    "    \n",
    "    \n",
    "    print(\"Collect gc\")\n",
    "    gc.collect()\n",
    "    print(\"Empty cache\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    print(\"Test phase\")\n",
    "    test(Data_loader_test_hombres)\n",
    "    \n",
    "    print(\"Saving test metrics...\")\n",
    "    dic2[\"stage\"].append([\"testing \" +str(epoch)])\n",
    "    dic2[\"loss\"].append([losses_list_test])\n",
    "    dic2[\"perplexity\"].append([perplexity_list_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./my_model_checkpoints_ellos_albeto/tokenizer_config.json',\n",
       " './my_model_checkpoints_ellos_albeto/special_tokens_map.json',\n",
       " './my_model_checkpoints_ellos_albeto/spiece.model',\n",
       " './my_model_checkpoints_ellos_albeto/added_tokens.json')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_h.save_pretrained('./my_model_checkpoints_ellos_albeto/')\n",
    "tokenizer_h.save_pretrained('./my_model_checkpoints_ellos_albeto/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_h(df):\n",
    "    data = df.tweet.to_numpy()\n",
    "    print(\"Encoding the corpus. This might take a while\")\n",
    "    embeddings = []\n",
    "    for sentence in data:\n",
    "        corpus_embeddings = tokenizer_h.encode(sentence)\n",
    "        corpus_embeddings = corpus_embeddings / np.linalg.norm(corpus_embeddings,keepdims=True)\n",
    "        embeddings.append(corpus_embeddings)\n",
    "        \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding the corpus. This might take a while\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3.0434495543502212e-05, 0.47057817009363123, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2.816794504997644e-05, 0.4355327663627357, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2.4246700123574846e-05, 0.00865607194411622, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.9428490717358174e-05, 0.3004033234717921, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3.210033407211136e-05, 0.4963353654229858, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201033</th>\n",
       "      <td>[4.567250645488207e-05, 0.7061882948053867, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201034</th>\n",
       "      <td>[2.82594103384097e-05, 0.4369470026524908, 1.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201035</th>\n",
       "      <td>[1.197675117408217e-05, 0.18518452665365853, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201036</th>\n",
       "      <td>[2.147609474603551e-05, 0.33206337696320104, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201037</th>\n",
       "      <td>[4.567250645488207e-05, 0.7061882948053867, 2....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201038 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       [3.0434495543502212e-05, 0.47057817009363123, ...\n",
       "1       [2.816794504997644e-05, 0.4355327663627357, 1....\n",
       "2       [2.4246700123574846e-05, 0.00865607194411622, ...\n",
       "3       [1.9428490717358174e-05, 0.3004033234717921, 9...\n",
       "4       [3.210033407211136e-05, 0.4963353654229858, 1....\n",
       "...                                                   ...\n",
       "201033  [4.567250645488207e-05, 0.7061882948053867, 2....\n",
       "201034  [2.82594103384097e-05, 0.4369470026524908, 1.4...\n",
       "201035  [1.197675117408217e-05, 0.18518452665365853, 5...\n",
       "201036  [2.147609474603551e-05, 0.33206337696320104, 1...\n",
       "201037  [4.567250645488207e-05, 0.7061882948053867, 2....\n",
       "\n",
       "[201038 rows x 1 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hombres_embeddings = encode_h(hombres)\n",
    "datos_encoded_h = pd.DataFrame([hombres_embeddings]).T\n",
    "datos_encoded_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_encoded_h.to_csv(\"./my_model_checkpoints_ellos_albeto/embeddings_albeto.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = list(df_metrics.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in seq[0]:\n",
    "    a.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "for i in a[0]:\n",
    "    b.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5026"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9bf90377c0>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0047140779854909b0ab62eb0451cd5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7f25d4da0db48b7a1b233daadaf2951",
      "max": 10052,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cc50281d7cff4e52947394e5b12611b0",
      "value": 0
     }
    },
    "1c6abc4da70147ddb9877e52dfeea14d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6d2d87b1038443fafff1bd69c138507",
      "placeholder": "​",
      "style": "IPY_MODEL_634ac1ee58484a539a79dee3f7af5e47",
      "value": "  0%"
     }
    },
    "36def7c352d8400cace4fb67dc06dccd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4290d0f0f4b34f16a05d888941f4619c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "634ac1ee58484a539a79dee3f7af5e47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f5c50d072db4cf4a83cd9e29868e8d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c6abc4da70147ddb9877e52dfeea14d",
       "IPY_MODEL_0047140779854909b0ab62eb0451cd5f",
       "IPY_MODEL_cd4a015ff8b04c8e8d267bdfbbe3864c"
      ],
      "layout": "IPY_MODEL_36def7c352d8400cace4fb67dc06dccd"
     }
    },
    "9027d121739e46108aa64acaa807c0ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7f25d4da0db48b7a1b233daadaf2951": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6d2d87b1038443fafff1bd69c138507": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc50281d7cff4e52947394e5b12611b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cd4a015ff8b04c8e8d267bdfbbe3864c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9027d121739e46108aa64acaa807c0ba",
      "placeholder": "​",
      "style": "IPY_MODEL_4290d0f0f4b34f16a05d888941f4619c",
      "value": " 0/10052 [00:00&lt;?, ?it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
